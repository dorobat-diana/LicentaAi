{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorobat-diana/LicentaAi/blob/main/OneShotSeamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7MzAC2os4rbF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, BatchNormalization\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    print(\"Google Drive already mounted or mount failed.\")\n",
        "\n",
        "SIAMESE_MODEL_PATH = '/content/drive/MyDrive/ColabNotebooks/results/siamese_mobilenetv2_landmark_model_phase2_toplayers.keras'\n",
        "\n",
        "BASE_MODEL_PATH_FOR_STRUCTURE = '/content/drive/MyDrive/ColabNotebooks/results/MobileNetV2_FamousPlaces/phase3_with_dropout_l2.keras'\n",
        "FEATURE_LAYER_NAME_FOR_STRUCTURE = 'global_average_pooling2d_1'\n",
        "\n",
        "N_LAYERS_UNFROZEN_IN_SAVED_FEATURE_EXTRACTOR = 10\n",
        "\n",
        "DATA_DIR_FOR_ONESHOT = '/content/drive/MyDrive/ColabNotebooks/data/famous_places/split/test'\n",
        "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
        "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "N_WAY = 5\n",
        "N_TRIALS = 500\n",
        "\n",
        "def load_and_preprocess_image_tf(path_tensor, img_shape=(IMG_WIDTH, IMG_HEIGHT, 3)):\n",
        "    img = tf.io.read_file(path_tensor)\n",
        "    try:\n",
        "        img = tf.image.decode_image(img, channels=img_shape[2], expand_animations=False)\n",
        "    except tf.errors.InvalidArgumentError:\n",
        "        tf.print(f\"Warning: Could not decode image {path_tensor}. Returning zeros.\")\n",
        "        return tf.zeros(img_shape, dtype=tf.float32)\n",
        "    if len(img.shape) != 3 or img.shape[2] != img_shape[2]:\n",
        "        tf.print(f\"Warning: Image {path_tensor} has unexpected shape {img.shape}. Converting or returning zeros.\")\n",
        "        if img.shape[2] == 1: img = tf.image.grayscale_to_rgb(img)\n",
        "        elif img.shape[2] == 4: img = img[:,:,:3]\n",
        "        else: return tf.zeros(img_shape, dtype=tf.float32)\n",
        "    img = tf.image.resize(img, [img_shape[0], img_shape[1]])\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "def predict_similarity_oneshot(img_path1, img_path2, model, img_shape):\n",
        "    if model is None: return None\n",
        "    img1_tensor = load_and_preprocess_image_tf(tf.constant(img_path1), img_shape)\n",
        "    img2_tensor = load_and_preprocess_image_tf(tf.constant(img_path2), img_shape)\n",
        "    if tf.reduce_sum(img1_tensor) == 0 or tf.reduce_sum(img2_tensor) == 0:\n",
        "        print(f\"Warning: One or both images for similarity check might not have loaded correctly.\")\n",
        "        return 0.0\n",
        "    img1_batch = tf.expand_dims(img1_tensor, axis=0)\n",
        "    img2_batch = tf.expand_dims(img2_tensor, axis=0)\n",
        "    try:\n",
        "        prediction = model.predict([img1_batch, img2_batch], verbose=0)\n",
        "        return prediction[0][0]\n",
        "    except Exception as e:\n",
        "        return 0.0\n",
        "\n",
        "def build_siamese_model_for_weight_loading(input_shape, feature_extractor_model_instance):\n",
        "    \"\"\"\n",
        "    Builds the Siamese network model structure, ensuring all layer names match\n",
        "    the model from which weights will be loaded.\n",
        "    Uses tf.* ops in Lambda for robustness.\n",
        "    \"\"\"\n",
        "    input_a = Input(shape=input_shape, name=\"input_image_A\")\n",
        "    input_b = Input(shape=input_shape, name=\"input_image_B\")\n",
        "\n",
        "    processed_a = feature_extractor_model_instance(input_a)\n",
        "    processed_b = feature_extractor_model_instance(input_b)\n",
        "\n",
        "    distance_layer = Lambda(\n",
        "        lambda tensors: tf.reduce_sum(tf.abs(tensors[0] - tensors[1]), axis=1, keepdims=True),\n",
        "        output_shape=(1,),\n",
        "        name=\"L1_distance\"\n",
        "    )\n",
        "    distance = distance_layer([processed_a, processed_b])\n",
        "\n",
        "    x = Dense(128, activation='relu', name=\"head_dense_1\")(distance)\n",
        "    x = Dropout(0.3, name=\"head_dropout_1\")(x)\n",
        "    x = Dense(64, activation='relu', name=\"head_dense_2\")(x)\n",
        "    x = Dropout(0.3, name=\"head_dropout_2\")(x)\n",
        "    prediction = Dense(1, activation='sigmoid', name=\"similarity_prediction\")(x)\n",
        "\n",
        "    rebuilt_model = Model(inputs=[input_a, input_b], outputs=prediction)\n",
        "    return rebuilt_model\n",
        "\n",
        "print(\"Rebuilding Siamese model structure...\")\n",
        "siamese_model_rebuilt = None\n",
        "try:\n",
        "    print(f\"Loading base MobileNetV2 model from: {BASE_MODEL_PATH_FOR_STRUCTURE} for feature extractor structure...\")\n",
        "    base_mobilenet_model = load_model(BASE_MODEL_PATH_FOR_STRUCTURE)\n",
        "    print(\"Base MobileNetV2 model loaded.\")\n",
        "\n",
        "    feature_output_structure = base_mobilenet_model.get_layer(FEATURE_LAYER_NAME_FOR_STRUCTURE).output\n",
        "    feature_extractor_structure = Model(\n",
        "        inputs=base_mobilenet_model.input,\n",
        "        outputs=feature_output_structure,\n",
        "        name=\"feature_extractor_functional\"\n",
        "    )\n",
        "    print(f\"Feature extractor structure ('{feature_extractor_structure.name}') created.\")\n",
        "\n",
        "    print(f\"Setting trainability for layers in '{feature_extractor_structure.name}'...\")\n",
        "    for layer in feature_extractor_structure.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    if N_LAYERS_UNFROZEN_IN_SAVED_FEATURE_EXTRACTOR > 0:\n",
        "        unfrozen_count = 0\n",
        "        for layer in feature_extractor_structure.layers[-N_LAYERS_UNFROZEN_IN_SAVED_FEATURE_EXTRACTOR:]:\n",
        "            if not isinstance(layer, BatchNormalization):\n",
        "                layer.trainable = True\n",
        "                unfrozen_count += 1\n",
        "        print(f\"  Set {unfrozen_count} non-BN layers in feature extractor to trainable.\")\n",
        "    else:\n",
        "        print(\"  All layers in feature extractor kept frozen.\")\n",
        "    siamese_model_rebuilt = build_siamese_model_for_weight_loading(IMG_SHAPE, feature_extractor_structure)\n",
        "    print(\"Full Siamese model structure rebuilt.\")\n",
        "    print(f\"Loading weights from: {SIAMESE_MODEL_PATH}\")\n",
        "    siamese_model_rebuilt.load_weights(SIAMESE_MODEL_PATH)\n",
        "    print(\"Weights loaded successfully into rebuilt model.\")\n",
        "    siamese_model = siamese_model_rebuilt\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during model rebuilding or weight loading: {e}\")\n",
        "    raise SystemExit(\"Model construction/weight loading failed.\")\n",
        "\n",
        "def get_image_paths_by_class(directory):\n",
        "    image_paths = {}\n",
        "    class_names = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
        "    if not class_names: raise ValueError(f\"No subdirectories (classes) found in {directory}\")\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        paths_in_class = []\n",
        "        for fname in os.listdir(class_dir):\n",
        "            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                paths_in_class.append(os.path.join(class_dir, fname))\n",
        "        if paths_in_class:\n",
        "            if len(paths_in_class) >= 2: image_paths[class_name] = paths_in_class\n",
        "            else: print(f\"Warning: Class '{class_name}' has < 2 images, excluding.\")\n",
        "    return image_paths\n",
        "\n",
        "print(f\"\\nLoading image paths from: {DATA_DIR_FOR_ONESHOT}\")\n",
        "image_paths_by_class = get_image_paths_by_class(DATA_DIR_FOR_ONESHOT)\n",
        "if len(image_paths_by_class) < N_WAY:\n",
        "    raise ValueError(f\"Not enough classes for {N_WAY}-way one-shot. Found {len(image_paths_by_class)}.\")\n",
        "print(f\"Found {len(image_paths_by_class)} eligible classes.\")\n",
        "\n",
        "print(f\"\\nStarting {N_WAY}-way one-shot learning evaluation for {N_TRIALS} trials...\")\n",
        "correct_predictions = 0\n",
        "all_trial_details = []\n",
        "\n",
        "for trial in range(N_TRIALS):\n",
        "    selected_class_names = random.sample(list(image_paths_by_class.keys()), N_WAY)\n",
        "    support_set_images = {}\n",
        "    query_image_path = None\n",
        "    true_query_class = None\n",
        "\n",
        "    for i, class_name in enumerate(selected_class_names):\n",
        "        img1_path, img2_path = random.sample(image_paths_by_class[class_name], 2)\n",
        "        support_set_images[class_name] = img1_path\n",
        "        if i == 0:\n",
        "            query_image_path = img2_path\n",
        "            true_query_class = class_name\n",
        "\n",
        "    if query_image_path is None: continue\n",
        "\n",
        "    similarity_scores = {}\n",
        "    for class_name, support_img_path in support_set_images.items():\n",
        "        similarity = predict_similarity_oneshot(query_image_path, support_img_path, siamese_model, IMG_SHAPE)\n",
        "        similarity_scores[class_name] = similarity\n",
        "\n",
        "    if not similarity_scores: predicted_class = \"N/A\"\n",
        "    else: predicted_class = max(similarity_scores, key=similarity_scores.get)\n",
        "\n",
        "    is_correct = (predicted_class == true_query_class)\n",
        "    if is_correct: correct_predictions += 1\n",
        "\n",
        "    all_trial_details.append({\n",
        "        'trial_num': trial + 1,\n",
        "        'query_path': query_image_path,\n",
        "        'support_set': dict(support_set_images),\n",
        "        'true_class': true_query_class,\n",
        "        'predicted_class': predicted_class,\n",
        "        'scores': dict(similarity_scores)\n",
        "    })\n",
        "    if (trial + 1) % (N_TRIALS // 10 if N_TRIALS >=10 else 1) == 0:\n",
        "        print(f\"Completed Trial {trial+1}/{N_TRIALS}\")\n",
        "\n",
        "one_shot_accuracy = (correct_predictions / N_TRIALS) * 100 if N_TRIALS > 0 else 0\n",
        "print(f\"\\n--- One-Shot Learning Evaluation Summary ---\")\n",
        "print(f\"Total Trials: {N_TRIALS}\")\n",
        "print(f\"Correct Predictions: {correct_predictions}\")\n",
        "print(f\"Accuracy: {one_shot_accuracy:.2f}%\")\n",
        "\n",
        "def display_one_shot_task(trial_detail):\n",
        "    query_path = trial_detail['query_path']\n",
        "    support_set = trial_detail['support_set']\n",
        "    true_class = trial_detail['true_class']\n",
        "    predicted_class = trial_detail['predicted_class']\n",
        "    scores = trial_detail['scores']\n",
        "    trial_num = trial_detail['trial_num']\n",
        "\n",
        "    n_support = len(support_set)\n",
        "    plt.figure(figsize=(3 * (n_support + 1), 4))\n",
        "    plt.subplot(1, n_support + 1, 1)\n",
        "    try:\n",
        "        query_img = plt.imread(query_path)\n",
        "        plt.imshow(query_img)\n",
        "    except FileNotFoundError:\n",
        "        plt.text(0.5, 0.5, 'Query Img\\nNot Found', ha='center', va='center', color='red')\n",
        "    plt.title(f\"Query (True: {true_class})\\nPred: {predicted_class}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    i = 2\n",
        "    for cls, path in support_set.items():\n",
        "        plt.subplot(1, n_support + 1, i)\n",
        "        try:\n",
        "            support_img = plt.imread(path)\n",
        "            plt.imshow(support_img)\n",
        "        except FileNotFoundError:\n",
        "            plt.text(0.5, 0.5, f'{cls}\\nSupport Img\\nNot Found', ha='center', va='center', color='red')\n",
        "\n",
        "        title_color = 'black'\n",
        "        if cls == true_class and cls == predicted_class: title_color = 'blue'\n",
        "        elif cls == predicted_class: title_color = 'red'\n",
        "        elif cls == true_class: title_color = 'green'\n",
        "\n",
        "        plt.title(f\"Support: {cls}\\nScore: {scores.get(cls, 0):.2f}\", color=title_color)\n",
        "        plt.axis('off')\n",
        "        i += 1\n",
        "\n",
        "    plt.suptitle(f\"One-Shot Task Visualization - Trial {trial_num}\", fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n",
        "\n",
        "if all_trial_details:\n",
        "    print(\"\\nVisualizing a few one-shot task examples:\")\n",
        "    display_one_shot_task(all_trial_details[0])\n",
        "    first_incorrect = next((td for td in all_trial_details if td['predicted_class'] != td['true_class']), None)\n",
        "    if first_incorrect and first_incorrect['trial_num'] != all_trial_details[0]['trial_num']:\n",
        "        display_one_shot_task(first_incorrect)\n",
        "    elif len(all_trial_details) > 1 and first_incorrect is None :\n",
        "         display_one_shot_task(all_trial_details[1 % len(all_trial_details)])\n",
        "\n",
        "\n",
        "print(\"\\n--- One-Shot Evaluation Script Finished ---\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyP0SLgmCBDDny6FHBoN+6b0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}